{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**need some %run command and uncomment the model load before submitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,json\n",
    "from typing import Callable, Dict, List, Set, Tuple\n",
    "from elasticsearch import Elasticsearch\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "import datetime\n",
    "sys.path.insert(0, 'extract_features')\n",
    "from extract_No1to5_features import extract_features_1to5\n",
    "from extract_No11to12_features import extract_features_11to12\n",
    "from extract_No13to15_features import TypeTaxonomy, extract_features_13to15\n",
    "from extract_No16_feature import extract_features_16\n",
    "from extract_No17to19_features import get_analyze,extract_features_17to19\n",
    "from extract_No20to22_features import extract_features_20to22\n",
    "from extract_No23to25_features_optimized import extract_features_23to25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LAPTOP-ADBLIUPR',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': '5VELmBwJTk-urTuhZdTgew',\n",
       " 'version': {'number': '7.15.1',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'zip',\n",
       "  'build_hash': '83c34f456ae29d60e94d886e455e6a3409bba9ed',\n",
       "  'build_date': '2021-10-07T21:56:19.031608185Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.9.0',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce logging level.\n",
    "import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"elasticsearch\").disabled = True\n",
    "# es_log = logging.getLogger(\"elasticsearch\")\n",
    "# es_log.setLevel(logging.CRITICAL)\n",
    "es= Elasticsearch()\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run extract_features/extract_No11to12_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for my computer , need the following enviroment to run this script**\n",
    "<br>\n",
    "/c/Users/junec/anaconda3/python\n",
    "<br>\n",
    "/c/Users/junec/anaconda3/Scripts/pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/junec/anaconda3/python\n",
      "/c/Users/junec/anaconda3/Scripts/pip\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 22:50:39,596 : INFO : loading KeyedVectors object from googleNews.d2v\n",
      "2021-11-19 22:50:41,159 : INFO : loading vectors from googleNews.d2v.vectors.npy with mmap=None\n",
      "2021-11-19 22:51:10,008 : INFO : KeyedVectors lifecycle event {'fname': 'googleNews.d2v', 'datetime': '2021-11-19T22:51:09.970351', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "try:\n",
    "    model_loaded = gensim.models.keyedvectors.KeyedVectors.load('googleNews.d2v')\n",
    "except:\n",
    "    model_loaded = api.load('word2vec-google-news-300')\n",
    "    model_loaded.save('googleNews.d2v')\n",
    "    model_loaded = gensim.models.keyedvectors.KeyedVectors.load('googleNews.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files\n",
    "filepath=\"data/DBpedia_map_type_entities.json\"\n",
    "with open(filepath, 'r', encoding='utf-8') as file:\n",
    "    DBpedia_map_type_entities = json.load(file)\n",
    "    \n",
    "filepath=\"data/training_types.json\"\n",
    "with open(filepath,encoding='utf-8') as json_file:\n",
    "    training_map_type_questions = json.load(json_file)\n",
    "\n",
    "filepath=\"data/ElasticSearch_map_type_docID.json\"\n",
    "with open(filepath, 'r',encoding='utf-8') as f:\n",
    "    docID_DBOtype_dict = json.load(f)\n",
    "\n",
    "filepath=\"../smart-dataset/datasets/DBpedia/smarttask_dbpedia_train.json\"\n",
    "with open(filepath, 'r') as f:\n",
    "    smarttask_dbpedia_train = json.load(f)\n",
    "\n",
    "typeobj=TypeTaxonomy(\"data/dbpedia_types.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_list=list(typeobj._types.keys())\n",
    "# type_list[1:]\n",
    "# len(type_list[1:]),len(smarttask_dbpedia_train) ,smarttask_dbpedia_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp_type=\"dbo:MilitaryPerson\"\n",
    "# question=\"Does the shelf life of spinach equal 8?\"\n",
    "\n",
    "# dp_type=\"dbo:MusicFestival\"\n",
    "# question=\"When was Bibi Andersson music festival married to Per Ahlmark very green?\"\n",
    "\n",
    "# extract_features_1to5(DBpedia_map_type_entities,dp_type,question,es)\n",
    "# features_1to5=extract_features_1to5(DBpedia_map_type_entities,dp_type,question,es)\n",
    "# extract_features_11to12(dp_type, question,docID_DBOtype_dict,es)\n",
    "# extract_features_13to15(typeobj,dp_type)\n",
    "# print(extract_features_16(DBpedia_map_type_entities,dp_type))\n",
    "\n",
    "# extract_features_17to19(training_map_type_questions,dp_type,question)\n",
    "# extract_features_20to22(dp_type,question)\n",
    "# extract_features_23to25(model_loaded,dp_type, question, mode=\"Euclidean\")\n",
    "# extract_features_23to25(model_loaded,dp_type, question, mode=\"similarities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_features_13to16(dp_type:str,\n",
    "                        typeobj:TypeTaxonomy,\n",
    "                        training_map_type_questions:Dict):\n",
    "    all_DBOtype=list(typeobj._types.keys())\n",
    "    #remove the first type:\"thing\"\n",
    "    all_DBOtype=all_DBOtype[1:]\n",
    "    dict_13to16={}\n",
    "    for DBOtype in all_DBOtype:\n",
    "        features_13to15 = extract_features_13to15(typeobj,dp_type)\n",
    "        #feature_vect =list(features_13to15.values())\n",
    "        dict_13to16.update(features_13to15)\n",
    "\n",
    "        features_16=extract_features_16(DBpedia_map_type_entities,dp_type)\n",
    "        #feature_vect.extend(list(features_16.values()))\n",
    "        dict_13to16.update(features_16)\n",
    "        print(dict_13to16)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    question:str,\n",
    "    dp_type: str,\n",
    "    DBpedia_map_type_entities:Dict,\n",
    "    docID_DBOtype_dict:Dict,\n",
    "    typeobj:TypeTaxonomy,\n",
    "    training_map_type_questions:Dict,\n",
    "    model_loaded:gensim.models.keyedvectors.KeyedVectors,\n",
    "    es: Elasticsearch,\n",
    "    analyze,X,terms_corpus,\n",
    "    add_extra_features:bool=False\n",
    ") -> List[float]:\n",
    "    \"\"\"Extracts features of a query and document pair.\n",
    "\n",
    "        Args:\n",
    "            query: string.\n",
    "            dp_type: DBO type.\n",
    "            es: Elasticsearch object instance.\n",
    "\n",
    "        Returns:\n",
    "            List of extracted feature values in a fixed order.\n",
    "    \"\"\"\n",
    "    features_1to5 = extract_features_1to5(DBpedia_map_type_entities,dp_type,question,es)\n",
    "    feature_vect = list(features_1to5.values())\n",
    "\n",
    "    features_11to12 = extract_features_11to12(dp_type, question,docID_DBOtype_dict,es)\n",
    "    feature_vect.extend(list(features_11to12.values()))\n",
    "\n",
    "    features_13to15 = extract_features_13to15(typeobj,dp_type)\n",
    "    feature_vect.extend(list(features_13to15.values()))\n",
    "    \n",
    "    features_16=extract_features_16(DBpedia_map_type_entities,dp_type)\n",
    "    feature_vect.extend(list(features_16.values()))\n",
    "    \n",
    "   \n",
    "    features_17to19=extract_features_17to19(analyze,X,terms_corpus,training_map_type_questions,dp_type,question)\n",
    "    feature_vect.extend(list(features_17to19.values()))\n",
    "    \n",
    "    features_20to22=extract_features_20to22(dp_type,question)\n",
    "    feature_vect.extend(list(features_20to22.values()))\n",
    "    \n",
    "    features_23to25=extract_features_23to25(model_loaded,dp_type, question, mode=\"Euclidean\")\n",
    "    feature_vect.extend(list(features_23to25.values()))\n",
    "\n",
    "    if add_extra_features:\n",
    "        features_23to25_variant=extract_features_23to25(model_loaded,dp_type, question, mode=\"similarities\")\n",
    "        feature_vect.extend(list(features_23to25_variant.values()))\n",
    "    \n",
    "    return feature_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junec\\anaconda3\\lib\\site-packages\\elasticsearch\\connection\\base.py:209: ElasticsearchWarning: [types removal] Specifying types in term vector requests is deprecated.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "analyze,X,terms_corpus=get_analyze(training_map_type_questions)\n",
    "dp_type=\"dbo:MusicFestival\"\n",
    "question=\"When was Bibi Andersson music festival married to Per Ahlmark very green?\"\n",
    "features=extract_features(\n",
    "                    question,\n",
    "                    dp_type,\n",
    "                    DBpedia_map_type_entities,\n",
    "                    docID_DBOtype_dict,\n",
    "                    typeobj,\n",
    "                    training_map_type_questions,\n",
    "                    model_loaded,\n",
    "                    es,\n",
    "                    analyze,X,terms_corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "101%100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------j: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junec\\anaconda3\\lib\\site-packages\\elasticsearch\\connection\\base.py:209: ElasticsearchWarning: [types removal] Specifying types in term vector requests is deprecated.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n",
      "C:\\Users\\junec\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\junec\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- 2021-11-19 23:00:18.964546\n",
      "--------------length of X_train:500 y_train: 500\n",
      "----------------- 2021-11-19 23:03:20.809202\n",
      "--------------length of X_train:1000 y_train: 1000\n",
      "----------------- 2021-11-19 23:05:23.304334\n",
      "--------------length of X_train:1500 y_train: 1500\n",
      "----------------- 2021-11-19 23:08:45.048753\n",
      "--------------length of X_train:2000 y_train: 2000\n",
      "----------------- 2021-11-19 23:11:23.782352\n",
      "--------------length of X_train:2500 y_train: 2500\n",
      "----------------- 2021-11-19 23:13:41.359858\n",
      "--------------length of X_train:3000 y_train: 3000\n",
      "----------------- 2021-11-19 23:17:01.777775\n",
      "--------------length of X_train:3500 y_train: 3500\n",
      "----------------- 2021-11-19 23:19:46.701009\n",
      "--------------length of X_train:4000 y_train: 4000\n",
      "----------------- 2021-11-19 23:21:54.572097\n",
      "--------------length of X_train:4500 y_train: 4500\n",
      "----------------- 2021-11-19 23:31:46.481838\n",
      "--------------length of X_train:5000 y_train: 5000\n",
      "----------------- 2021-11-19 23:39:23.826522\n",
      "--------------length of X_train:5500 y_train: 5500\n",
      "----------------- 2021-11-19 23:41:55.329967\n",
      "--------------length of X_train:6000 y_train: 6000\n",
      "----------------- 2021-11-19 23:44:39.526062\n",
      "--------------length of X_train:6500 y_train: 6500\n",
      "----------------- 2021-11-19 23:48:26.521104\n",
      "--------------length of X_train:7000 y_train: 7000\n",
      "------------error for type: dbo:Airline Who is the pupil of the tutor Miguel Ángel Estrella?\n",
      "Unexpected ConnectionTimeout caused by - ReadTimeoutError(HTTPConnectionPool(host='localhost', port=9200): Read timed out. (read timeout=10)), <class 'elasticsearch.exceptions.ConnectionTimeout'>\n"
     ]
    },
    {
     "ename": "ConnectionTimeout",
     "evalue": "ConnectionTimeout caused by - ReadTimeoutError(HTTPConnectionPool(host='localhost', port=9200): Read timed out. (read timeout=10))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    420\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mtimeout\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[0;32m    251\u001b[0m             response = self.pool.urlopen(\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    719\u001b[0m             retries = retries.increment(\n\u001b[1;32m--> 720\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[1;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    330\u001b[0m             raise ReadTimeoutError(\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Read timed out. (read timeout=%s)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             )\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPConnectionPool(host='localhost', port=9200): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionTimeout\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7e50f7272377>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m                                         \u001b[0mtraining_map_type_questions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                                         \u001b[0mmodel_loaded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                                         es) \n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-7e50f7272377>\u001b[0m in \u001b[0;36mprepare_training_data\u001b[1;34m(smarttask_dbpedia_train, DBpedia_map_type_entities, docID_DBOtype_dict, typeobj, training_map_type_questions, model_loaded, es, add_extra_features)\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0mmodel_loaded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                     \u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                     analyze,X,terms_corpus) \n\u001b[0m\u001b[0;32m     41\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------------error for type:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDBOtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-85437006d505>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(question, dp_type, DBpedia_map_type_entities, docID_DBOtype_dict, typeobj, training_map_type_questions, model_loaded, es, analyze, X, terms_corpus, add_extra_features)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfixed\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mfeatures_1to5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features_1to5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDBpedia_map_type_entities\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdp_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mfeature_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_1to5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\cs\\courses_term3\\DAT640_ Information_Retrieval\\project\\dat640-smart-task\\advanced-type-prediction\\extract_features\\extract_No1to5_features.py\u001b[0m in \u001b[0;36mextract_features_1to5\u001b[1;34m(DBpedia_map_type_entities, dp_type, query, es, k_list, index)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mECBM25_t_q\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mk_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mhits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_source\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hits\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hits\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mscore_list\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"_score\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mw_e_t\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDBpedia_map_type_entities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdp_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\client\\utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\client\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[0;32m   1768\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1769\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1770\u001b[1;33m             \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    456\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    424\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[0mignore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m                 )\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"N/A\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mConnectionTimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TIMEOUT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"N/A\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionTimeout\u001b[0m: ConnectionTimeout caused by - ReadTimeoutError(HTTPConnectionPool(host='localhost', port=9200): Read timed out. (read timeout=10))"
     ]
    }
   ],
   "source": [
    "def prepare_training_data(  smarttask_dbpedia_train:List[Dict],\n",
    "                            DBpedia_map_type_entities:Dict[str,List],\n",
    "                            docID_DBOtype_dict:Dict[str,str],\n",
    "                            typeobj:TypeTaxonomy,\n",
    "                            training_map_type_questions:Dict[str,str],\n",
    "                            model_loaded:gensim.models.keyedvectors.KeyedVectors,\n",
    "                            es: Elasticsearch,\n",
    "                            add_extra_features:bool=False)-> Tuple[List[List[float]], List[int]]:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    all_DBOtype=list(typeobj._types.keys())\n",
    "    #remove the first type:\"thing\"\n",
    "    all_DBOtype=all_DBOtype[1:]\n",
    "    analyze,X,terms_corpus=get_analyze(training_map_type_questions)\n",
    "    count=0\n",
    "    j=0\n",
    "    for entry in smarttask_dbpedia_train:\n",
    "#         if j%int(len(smarttask_dbpedia_train)/100)==0:\n",
    "#             print(f'--------------{j/int(len(smarttask_dbpedia_train)/100)}% is finished')\n",
    "        if j%100==0:\n",
    "            print(\"--------------------j:\",j)\n",
    "        \n",
    "        j+=1\n",
    "        if entry['question']==None:\n",
    "            continue\n",
    "        if entry['category']=='resource':\n",
    "            for DBOtype in all_DBOtype: \n",
    "                try:\n",
    "                    features=extract_features(\n",
    "                    entry['question'],\n",
    "                    DBOtype,\n",
    "                    DBpedia_map_type_entities,\n",
    "                    docID_DBOtype_dict,\n",
    "                    typeobj,\n",
    "                    training_map_type_questions,\n",
    "                    model_loaded,\n",
    "                    es,\n",
    "                    analyze,X,terms_corpus) \n",
    "                except BaseException as err:\n",
    "                    print(\"------------error for type:\",DBOtype,entry['question'])\n",
    "                    print(f\"Unexpected {err}, {type(err)}\")  \n",
    "                    raise\n",
    "                X_train.append(features)\n",
    "                count+=1\n",
    "                #print(f'--------------length of X_train:{len(X_train)} y_train: {len(y_train)}')\n",
    "                if DBOtype in entry['type']: \n",
    "                    y_train.append(1)\n",
    "                else:\n",
    "                    y_train.append(0)\n",
    "                    \n",
    "                if count%100000==0:\n",
    "                    print(f'--------------{count} is finished')\n",
    "                if len(X_train)%500==0:\n",
    "                    print(\"-----------------\",datetime.datetime.now())\n",
    "                    print(f'--------------length of X_train:{len(X_train)} y_train: {len(y_train)}')\n",
    "        \n",
    "    print(f'{count} features has been saved,{j} questions have been processed')\n",
    "    return X_train,y_train\n",
    "\n",
    "\n",
    "# with open(\"../data/training_types.json\", 'w',encoding='utf-8') as f:\n",
    "#   json.dump(collections, f, ensure_ascii=False)\n",
    "\n",
    "X_train,y_train=prepare_training_data(smarttask_dbpedia_train,\n",
    "                                        DBpedia_map_type_entities,\n",
    "                                        docID_DBOtype_dict,\n",
    "                                        typeobj,\n",
    "                                        training_map_type_questions,\n",
    "                                        model_loaded,\n",
    "                                        es) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/X_train.json\", 'w') as f:\n",
    "  json.dump(collections, f)\n",
    "with open(\"../data/y_train.json\", 'w') as f:\n",
    "  json.dump(collections, f)\n",
    "print(\"X_train,y_train are saved as json files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es=Elasticsearch()\n",
    "# es.get(index='dbpdiea_type_centric',id=\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index='dbpdiea_type_centric'\n",
    "# field=\"abstract\"\n",
    "# tv = es.termvectors(index=index, doc_type=\"_doc\", id=\"1\", fields=field, term_statistics=True) \n",
    "# collection_len=tv[\"term_vectors\"][field]['field_statistics']['sum_ttf']  \n",
    "# #total number of entity in the collections\n",
    "# doc_number=tv[\"term_vectors\"][field]['field_statistics']['doc_count'] \n",
    "# #average document length\n",
    "# avgdl=collection_len/doc_number\n",
    "# collection_len,doc_number,avgdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word=\"theatre\"\n",
    "# #model_loaded[word]\n",
    "# model_loaded.most_similar(positive=[word], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
