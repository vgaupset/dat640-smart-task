{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\junec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import modules and set up logging.\n",
    "from typing import Callable, Dict, List, Set, Tuple, Generator\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to download the pretrained model of 'word2vec-google-news-300'\n",
    "#make sure to use a 64 bit python\n",
    "import struct\n",
    "struct.calcsize(\"P\") * 8\n",
    "#!which python\n",
    "#!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging level.\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 01:31:59,491 : INFO : loading projection weights from C:\\Users\\junec/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2021-11-10 01:32:47,777 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:\\\\Users\\\\junec/gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2021-11-10T01:32:47.773867', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "model_loaded = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/57507832/unable-to-allocate-array-with-shape-and-data-type\n",
    "#model_loaded.save('googleNews.d2v')\n",
    "#model_loaded = gensim.models.keyedvectors.KeyedVectors.load('googleNews.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_WORD_TYPE=[\"noun\",\"adj\",\"verb\",\"adv\"]\n",
    "POS_TAGS=[\"NN\",\"JJ\",\"VB\",\"RB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDBOtype(dp_type:str)->str:\n",
    "    dp_type=dp_type[len(\"dbo:\"):]\n",
    "    splitted_type=re.findall('[A-Z][a-z]*', dp_type)\n",
    "    return \" \".join(splitted_type).lower()\n",
    "    #return \" \".join(splitted_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_word_POStag(sentence:str)->Dict:\n",
    "    \"\"\"\n",
    "    parse content words of a sentence with their POS tag\n",
    "    argument:a sentence string\n",
    "    return:dictionary,key is POS tag and value is the corresponding word\n",
    "           a list of content words\n",
    "    \"\"\"\n",
    "    tag_dict={}\n",
    "    content_words=[]\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "    tagged_words=nltk.pos_tag(tokenized_sentence)\n",
    "    for POS_tag in POS_TAGS:\n",
    "        for word,tag in tagged_words:\n",
    "            if tag[:2]==POS_tag:\n",
    "                content_words.append(word)\n",
    "                temp=tag_dict.get(POS_tag,[])\n",
    "                temp.append(word)\n",
    "                tag_dict[POS_tag]=temp\n",
    "                #print(tag_dict[POS_tag])\n",
    "    return tag_dict,content_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pairwise_similarity(model_loaded,question_tagged:Dict,type_tagged:Dict)->List:\n",
    "    \"\"\"\n",
    "    calculate pairwise similarity between \n",
    "    content words in the query and the type label\n",
    "    \"\"\"\n",
    "    similarities=[]\n",
    "    for POS_tag,words in type_tagged.items():\n",
    "        if POS_tag in question_tagged.keys():\n",
    "            for word1 in words:\n",
    "                for word2 in question_tagged[POS_tag]:\n",
    "                    try:\n",
    "                        similarities.append(model_loaded.similarity(word1,word2))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "    return similarities\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_23to25(model_loaded,dp_type:str, question:str)->Tuple[float,float,float]:\n",
    "    #get content words and parse dictonary\n",
    "    question_tagged,question_content=parse_word_POStag(question)\n",
    "    processed_type=preprocessDBOtype(dp_type)\n",
    "    type_tagged,type_content=parse_word_POStag(processed_type)\n",
    "    #get centroid\n",
    "    question_centrality=model_loaded.rank_by_centrality(question_content, use_norm=True)\n",
    "    type_centrality=model_loaded.rank_by_centrality(type_content, use_norm=True)\n",
    "    question_centroid=question_centrality[0][1]\n",
    "    type_centroid=type_centrality[0][1]\n",
    "    #feature 23\n",
    "    sim_aggr=round(model_loaded.similarity(question_centroid, type_centroid),4)\n",
    "    \n",
    "    pairwise_similarity=calc_pairwise_similarity(model_loaded,question_tagged,type_tagged)\n",
    "    #feature 24,25\n",
    "    sim_max=max(pairwise_similarity)\n",
    "    sim_avg=round(sum(pairwise_similarity)/len(pairwise_similarity),4)\n",
    "    \n",
    "    return sim_aggr,sim_max,sim_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0196, 0.13620232, 0.0312)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_type=\"dbo:GreatMusicFestival\"\n",
    "question=\"When was Bibi Andersson married to Per Ahlmark very green?\"\n",
    "extract_features_23to25(model_loaded,dp_type, question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 01:47:33,161 : INFO : collecting all words and their counts\n",
      "2021-11-10 01:47:33,207 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_records': 1701, 'record_format': 'list of str (tokens)', 'file_size': 33182058, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py', 'license': 'not found', 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.', 'checksum': '68799af40b6bda07dfa47a32612e5364', 'file_name': 'text8.gz', 'read_more': ['http://mattmahoney.net/dc/textdata.html'], 'parts': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 01:47:38,357 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2021-11-10 01:47:38,358 : INFO : Creating a fresh vocabulary\n",
      "2021-11-10 01:47:38,677 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 71290 unique words (28.083071371733357%% of original 253854, drops 182564)', 'datetime': '2021-11-10T01:47:38.676741', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-11-10 01:47:38,679 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 16718844 word corpus (98.3160275555599%% of original 17005207, drops 286363)', 'datetime': '2021-11-10T01:47:38.679745', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-11-10 01:47:39,097 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2021-11-10 01:47:39,110 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2021-11-10 01:47:39,111 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 12506280.016269669 word corpus (74.8%% of prior 16718844)', 'datetime': '2021-11-10T01:47:39.111396', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-11-10 01:47:39,838 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
      "2021-11-10 01:47:39,838 : INFO : resetting layer weights\n",
      "2021-11-10 01:47:39,884 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-11-10T01:47:39.884592', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-11-10 01:47:39,885 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 71290 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-11-10T01:47:39.885607', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-11-10 01:47:40,899 : INFO : EPOCH 1 - PROGRESS: at 9.76% examples, 1210405 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:41,901 : INFO : EPOCH 1 - PROGRESS: at 19.17% examples, 1190513 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:42,906 : INFO : EPOCH 1 - PROGRESS: at 29.16% examples, 1211616 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:43,909 : INFO : EPOCH 1 - PROGRESS: at 38.21% examples, 1193683 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:44,920 : INFO : EPOCH 1 - PROGRESS: at 47.33% examples, 1181477 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:45,924 : INFO : EPOCH 1 - PROGRESS: at 53.15% examples, 1105704 words/s, in_qsize 4, out_qsize 0\n",
      "2021-11-10 01:47:46,941 : INFO : EPOCH 1 - PROGRESS: at 58.20% examples, 1036315 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:47,943 : INFO : EPOCH 1 - PROGRESS: at 63.02% examples, 982400 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:48,947 : INFO : EPOCH 1 - PROGRESS: at 68.08% examples, 943450 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:49,951 : INFO : EPOCH 1 - PROGRESS: at 76.90% examples, 957998 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:47:50,952 : INFO : EPOCH 1 - PROGRESS: at 86.89% examples, 983821 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:47:51,953 : INFO : EPOCH 1 - PROGRESS: at 95.88% examples, 995380 words/s, in_qsize 4, out_qsize 0\n",
      "2021-11-10 01:47:52,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-10 01:47:52,403 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-10 01:47:52,407 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-10 01:47:52,408 : INFO : EPOCH - 1 : training on 17005207 raw words (12508319 effective words) took 12.5s, 999803 effective words/s\n",
      "2021-11-10 01:47:53,426 : INFO : EPOCH 2 - PROGRESS: at 8.64% examples, 1056628 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:54,426 : INFO : EPOCH 2 - PROGRESS: at 13.40% examples, 826736 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:55,432 : INFO : EPOCH 2 - PROGRESS: at 18.46% examples, 760655 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:56,443 : INFO : EPOCH 2 - PROGRESS: at 23.10% examples, 714339 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:57,444 : INFO : EPOCH 2 - PROGRESS: at 28.75% examples, 713915 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:58,449 : INFO : EPOCH 2 - PROGRESS: at 38.80% examples, 805344 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:47:59,451 : INFO : EPOCH 2 - PROGRESS: at 47.91% examples, 853149 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:00,453 : INFO : EPOCH 2 - PROGRESS: at 57.67% examples, 899319 words/s, in_qsize 4, out_qsize 0\n",
      "2021-11-10 01:48:01,453 : INFO : EPOCH 2 - PROGRESS: at 66.84% examples, 926878 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:02,477 : INFO : EPOCH 2 - PROGRESS: at 71.72% examples, 893553 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:03,482 : INFO : EPOCH 2 - PROGRESS: at 75.78% examples, 857549 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:04,487 : INFO : EPOCH 2 - PROGRESS: at 80.66% examples, 835997 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:05,492 : INFO : EPOCH 2 - PROGRESS: at 85.30% examples, 816083 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:06,506 : INFO : EPOCH 2 - PROGRESS: at 89.89% examples, 798264 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:07,507 : INFO : EPOCH 2 - PROGRESS: at 95.12% examples, 788268 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:08,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-10 01:48:08,017 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-10 01:48:08,021 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-10 01:48:08,022 : INFO : EPOCH - 2 : training on 17005207 raw words (12504984 effective words) took 15.6s, 801081 effective words/s\n",
      "2021-11-10 01:48:09,027 : INFO : EPOCH 3 - PROGRESS: at 9.52% examples, 1180397 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:10,031 : INFO : EPOCH 3 - PROGRESS: at 19.75% examples, 1225207 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:11,033 : INFO : EPOCH 3 - PROGRESS: at 28.92% examples, 1202042 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:12,034 : INFO : EPOCH 3 - PROGRESS: at 34.86% examples, 1089603 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:13,039 : INFO : EPOCH 3 - PROGRESS: at 40.04% examples, 1000821 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:14,039 : INFO : EPOCH 3 - PROGRESS: at 45.09% examples, 939918 words/s, in_qsize 4, out_qsize 0\n",
      "2021-11-10 01:48:15,046 : INFO : EPOCH 3 - PROGRESS: at 49.85% examples, 890431 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:16,048 : INFO : EPOCH 3 - PROGRESS: at 58.26% examples, 910718 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:17,051 : INFO : EPOCH 3 - PROGRESS: at 68.49% examples, 951557 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:18,055 : INFO : EPOCH 3 - PROGRESS: at 78.66% examples, 981833 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:19,058 : INFO : EPOCH 3 - PROGRESS: at 87.95% examples, 997485 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:20,069 : INFO : EPOCH 3 - PROGRESS: at 94.30% examples, 979537 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:21,069 : INFO : EPOCH 3 - PROGRESS: at 99.41% examples, 953221 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:21,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-10 01:48:21,171 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-10 01:48:21,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-10 01:48:21,180 : INFO : EPOCH - 3 : training on 17005207 raw words (12505188 effective words) took 13.2s, 950552 effective words/s\n",
      "2021-11-10 01:48:22,191 : INFO : EPOCH 4 - PROGRESS: at 4.59% examples, 571611 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 01:48:23,214 : INFO : EPOCH 4 - PROGRESS: at 8.88% examples, 543838 words/s, in_qsize 5, out_qsize 1\n",
      "2021-11-10 01:48:24,225 : INFO : EPOCH 4 - PROGRESS: at 13.05% examples, 533922 words/s, in_qsize 4, out_qsize 1\n",
      "2021-11-10 01:48:25,236 : INFO : EPOCH 4 - PROGRESS: at 21.99% examples, 676585 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:26,242 : INFO : EPOCH 4 - PROGRESS: at 29.45% examples, 728754 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:27,244 : INFO : EPOCH 4 - PROGRESS: at 34.63% examples, 716479 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:28,258 : INFO : EPOCH 4 - PROGRESS: at 42.45% examples, 752459 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:29,268 : INFO : EPOCH 4 - PROGRESS: at 47.74% examples, 740745 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:30,285 : INFO : EPOCH 4 - PROGRESS: at 52.73% examples, 726857 words/s, in_qsize 5, out_qsize 1\n",
      "2021-11-10 01:48:31,303 : INFO : EPOCH 4 - PROGRESS: at 57.79% examples, 716513 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:32,308 : INFO : EPOCH 4 - PROGRESS: at 62.02% examples, 699470 words/s, in_qsize 4, out_qsize 0\n",
      "2021-11-10 01:48:33,320 : INFO : EPOCH 4 - PROGRESS: at 66.49% examples, 687288 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:34,327 : INFO : EPOCH 4 - PROGRESS: at 75.66% examples, 721499 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:35,333 : INFO : EPOCH 4 - PROGRESS: at 85.54% examples, 756801 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:36,334 : INFO : EPOCH 4 - PROGRESS: at 95.65% examples, 790056 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:36,781 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-10 01:48:36,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-10 01:48:36,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-10 01:48:36,791 : INFO : EPOCH - 4 : training on 17005207 raw words (12506071 effective words) took 15.6s, 801423 effective words/s\n",
      "2021-11-10 01:48:37,799 : INFO : EPOCH 5 - PROGRESS: at 7.23% examples, 893069 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:38,818 : INFO : EPOCH 5 - PROGRESS: at 12.29% examples, 754796 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:39,826 : INFO : EPOCH 5 - PROGRESS: at 17.17% examples, 704826 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:40,827 : INFO : EPOCH 5 - PROGRESS: at 21.75% examples, 671954 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:41,837 : INFO : EPOCH 5 - PROGRESS: at 26.34% examples, 652402 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:42,837 : INFO : EPOCH 5 - PROGRESS: at 32.69% examples, 677628 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:43,838 : INFO : EPOCH 5 - PROGRESS: at 42.86% examples, 762988 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:44,839 : INFO : EPOCH 5 - PROGRESS: at 53.03% examples, 826898 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:45,840 : INFO : EPOCH 5 - PROGRESS: at 62.79% examples, 870716 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:46,849 : INFO : EPOCH 5 - PROGRESS: at 70.37% examples, 877958 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:47,855 : INFO : EPOCH 5 - PROGRESS: at 75.49% examples, 855451 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:48,861 : INFO : EPOCH 5 - PROGRESS: at 80.36% examples, 833772 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:49,868 : INFO : EPOCH 5 - PROGRESS: at 85.48% examples, 818466 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:50,870 : INFO : EPOCH 5 - PROGRESS: at 90.42% examples, 804222 words/s, in_qsize 5, out_qsize 0\n",
      "2021-11-10 01:48:51,880 : INFO : EPOCH 5 - PROGRESS: at 95.53% examples, 792404 words/s, in_qsize 6, out_qsize 0\n",
      "2021-11-10 01:48:52,686 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-10 01:48:52,689 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-10 01:48:52,693 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-10 01:48:52,695 : INFO : EPOCH - 5 : training on 17005207 raw words (12506146 effective words) took 15.9s, 786568 effective words/s\n",
      "2021-11-10 01:48:52,695 : INFO : Word2Vec lifecycle event {'msg': 'training on 85026035 raw words (62530708 effective words) took 72.8s, 858825 effective words/s', 'datetime': '2021-11-10T01:48:52.695950', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-11-10 01:48:52,697 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=71290, vector_size=100, alpha=0.025)', 'datetime': '2021-11-10T01:48:52.697946', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "#try another model\n",
    "print(api.info('text8'))\n",
    "text8_corpus = api.load('text8')\n",
    "model = Word2Vec(text8_corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 02:19:48,907 : WARNING : vectors for words {'Bibi', 'Per', 'Andersson', 'Ahlmark'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0572, -0.062192805, -0.0622)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=model.wv\n",
    "dp_type=\"dbo:GreatMusicFestival\"\n",
    "question=\"When was Bibi Andersson married to Per Ahlmark very green?\"\n",
    "extract_features_23to25(model,dp_type, question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
