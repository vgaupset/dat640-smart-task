{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------preparing training data for knowledge base features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\junec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\junec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import sys,json,re,string\n",
    "from typing import Callable, Dict, List, Set, Tuple\n",
    "from elasticsearch import Elasticsearch\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "import datetime\n",
    "import csv\n",
    "sys.path.insert(1, 'extract_features')\n",
    "sys.path.insert(1, 'util')\n",
    "from helper_function import preprocess\n",
    "from extract_No1to5_features import extract_features_1to5\n",
    "from extract_No11to12_features import extract_features_11to12\n",
    "from extract_No13to15_features import TypeTaxonomy, extract_features_13to15\n",
    "from extract_No16_feature import extract_features_16\n",
    "from extract_No17to19_features import get_analyze,extract_features_17to19\n",
    "from extract_No20to22_features import extract_features_20to22\n",
    "from extract_No23to25_features_optimized import extract_features_23to25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LAPTOP-ADBLIUPR',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': '5VELmBwJTk-urTuhZdTgew',\n",
       " 'version': {'number': '7.15.1',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'zip',\n",
       "  'build_hash': '83c34f456ae29d60e94d886e455e6a3409bba9ed',\n",
       "  'build_date': '2021-10-07T21:56:19.031608185Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.9.0',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce logging level.\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"elasticsearch\").disabled = True\n",
    "es= Elasticsearch(timeout=600)\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for my computer , need the following enviroment to run this script**\n",
    "<br>\n",
    "/c/Users/junec/anaconda3/python\n",
    "<br>\n",
    "/c/Users/junec/anaconda3/Scripts/pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files\n",
    "# filepath=\"data/DBpedia_map_type_entities.json\"\n",
    "# with open(filepath, 'r', encoding='utf-8') as file:\n",
    "#     DBpedia_map_type_entities = json.load(file)\n",
    "    \n",
    "# filepath=\"data/training_types.json\"\n",
    "# with open(filepath,encoding='utf-8') as json_file:\n",
    "#     training_map_type_questions = json.load(json_file)\n",
    "\n",
    "# filepath=\"data/ElasticSearch_map_type_docID.json\"\n",
    "# with open(filepath, 'r',encoding='utf-8') as f:\n",
    "#     docID_DBOtype_dict = json.load(f)\n",
    "\n",
    "filepath=\"../smart-dataset/datasets/DBpedia/smarttask_dbpedia_train.json\"\n",
    "with open(filepath, 'r') as f:\n",
    "    smarttask_dbpedia_train = json.load(f)\n",
    "\n",
    "filepath=\"data/Knowledgebase_map_type_features_13to16.json\"\n",
    "with open(filepath, 'r',encoding='utf-8') as f:\n",
    "    map_type_featureVectors13to16 = json.load(f)\n",
    "    \n",
    "    \n",
    "\n",
    "# typeobj=TypeTaxonomy(\"data/dbpedia_types.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_knowlegebase(\n",
    "    dp_type: str,\n",
    "    map_type_featureVectors13to16:Dict\n",
    ") -> List[float]:\n",
    "    \"\"\"Extracts features of a query and document pair.\n",
    "\n",
    "        Args:\n",
    "            query: string.\n",
    "            dp_type: DBO type.\n",
    "            es: Elasticsearch object instance.\n",
    "\n",
    "        Returns:\n",
    "            List of extracted feature values in a fixed order.\n",
    "    \"\"\"\n",
    "    return map_type_featureVectors13to16[dp_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.429, 0, 11, 440]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_type=\"dbo:MusicFestival\"\n",
    "extract_features_knowlegebase(\n",
    "    dp_type,\n",
    "    map_type_featureVectors13to16\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------j: 0\n",
      "--------------------count: 0\n",
      "----------------- 2021-11-20 17:29:49.602767\n",
      "question_processed: What is the name of the opera based on Twelfth Night  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4c37b09c0481>\u001b[0m in \u001b[0;36mprepare_training_data_knowlegebase\u001b[1;34m(smarttask_dbpedia_train, map_type_featureVectors13to16, es)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 hits = es.search(\n\u001b[1;32m---> 49\u001b[1;33m                     \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dbpdiea_type_centric\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_source\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                 )[\"hits\"][\"hits\"]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\client\\utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\client\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[0;32m   1769\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1770\u001b[1;33m             \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1771\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    468\u001b[0m                     data = self.deserializer.loads(\n\u001b[1;32m--> 469\u001b[1;33m                         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"content-type\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m                     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\serializer.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(self, s, mimetype)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\elasticsearch\\serializer.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4c37b09c0481>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m prepare_training_data_knowlegebase(smarttask_dbpedia_train,\n\u001b[0;32m     73\u001b[0m                                         \u001b[0mmap_type_featureVectors13to16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m                                         es) \n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-4c37b09c0481>\u001b[0m in \u001b[0;36mprepare_training_data_knowlegebase\u001b[1;34m(smarttask_dbpedia_train, map_type_featureVectors13to16, es)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{count} features has been saved,{j} questions have been processed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#with first path filter\n",
    "def prepare_training_data_knowlegebase( smarttask_dbpedia_train:List[Dict],\n",
    "                            map_type_featureVectors13to16:Dict[str,List[float]],\n",
    "                            es: Elasticsearch\n",
    "                            )-> Tuple[List[List[float]], List[int]]:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    count=0\n",
    "    j=0\n",
    "    with open(\"data/for_training_knowlegebase.csv\", 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "\n",
    "        for entry in smarttask_dbpedia_train:\n",
    "            if j%100==0:\n",
    "                print(\"--------------------j:\",j)\n",
    "\n",
    "            j+=1\n",
    "            if entry['question']==None:\n",
    "                continue\n",
    "\n",
    "            question_processed=preprocess(entry['question'])\n",
    "\n",
    "            if entry['category']=='resource':\n",
    "                if count%50==0:\n",
    "                    print(\"--------------------count:\",count)\n",
    "                    print(\"-----------------\",datetime.datetime.now())\n",
    "                count+=1\n",
    "                print(\"question_processed:\",question_processed)\n",
    "                for DBOtype in entry['type']: \n",
    "                    try:\n",
    "                        features=extract_features_knowlegebase(dp_type,\n",
    "                                                                map_type_featureVectors13to16) \n",
    "                    except BaseException as err:\n",
    "                        print(\"------------error for type:\",DBOtype,entry['question'])\n",
    "                        print(f\"Unexpected {err}, {type(err)}\")  \n",
    "                        raise\n",
    "\n",
    "                    writer.writerow(features)\n",
    "                    writer.writerow([1])\n",
    "\n",
    "                #deal with top 30 documents\n",
    "                hits = es.search(\n",
    "                    index=\"dbpdiea_type_centric\", q=question_processed, _source=True, size=30\n",
    "                )[\"hits\"][\"hits\"]\n",
    "                rank_list= [hit['_source'][\"type\"] for hit in hits]\n",
    "\n",
    "                for DBOtype in rank_list:\n",
    "                    if DBOtype not in entry['type']:\n",
    "                        try:\n",
    "                            features=extract_features_knowlegebase(dp_type,\n",
    "                                                                    map_type_featureVectors13to16)\n",
    "                        except BaseException as err:\n",
    "                            print(\"------------error for type:\",DBOtype,entry['question'])\n",
    "                            print(f\"Unexpected {err}, {type(err)}\")  \n",
    "                            raise\n",
    "                        #print(features)\n",
    "\n",
    "                        writer.writerow(features)\n",
    "                        writer.writerow([0])\n",
    "\n",
    "    print(f'{count} features has been saved,{j} questions have been processed')\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "prepare_training_data_knowlegebase(smarttask_dbpedia_train,\n",
    "                                        map_type_featureVectors13to16,\n",
    "                                        es) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1,2,3,four,5\n",
    "# 1,2,3,four,5\n",
    "# 1,2,3,four,5\n",
    "import csv\n",
    "in_file = open(\"d:/in.csv\", \"rb\")\n",
    "reader = csv.reader(in_file)\n",
    "out_file = open(\"d:/out.csv\", \"wb\")\n",
    "writer = csv.writer(out_file)\n",
    "for row in reader:\n",
    "    row[3] = 4\n",
    "    writer.writerow(row)\n",
    "in_file.close()    \n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/knowledge_features.csv\")\n",
    "csvreader = csv.reader(file)\n",
    "rows = []\n",
    "for row in csvreader:\n",
    "        rows.append(row)\n",
    "rows\n",
    "\n",
    "type(rows[3])\n",
    "rows[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4] 1\n",
      "[1, 2, 3, 4] 0\n",
      "[1, 2, 3, 4] 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '[1, 2, 3, 4]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ad7688dcca7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_13to16'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_13to16'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '[1, 2, 3, 4]'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "features=[1,2,3,4]\n",
    "\n",
    "with open('names.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['X_13to16', 'y_label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'X_13to16': features, 'y_label': 1})\n",
    "    writer.writerow({'X_13to16': features, 'y_label': 0})\n",
    "    writer.writerow({'X_13to16': features, 'y_label': 1})\n",
    "    \n",
    "with open('names.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        print(row['X_13to16'], row['y_label'])\n",
    "        \n",
    "type(row['X_13to16']),type(row['y_label'])\n",
    "row['y_label']\n",
    "row['X_13to16']\n",
    "int(row['X_13to16'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
